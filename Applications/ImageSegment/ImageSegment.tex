\lab{Applications}{Image Segmentation}{Image Segmentation}

\objective{Understand some basic applications of eigenvalues to graph theory}
\label{lab:ImgSeg_eigenvalues}

\section*{Graph Theory}
\begin{figure}[h]
\includegraphics[width=\textwidth/2]{graphExample}
\caption{A simple undirected graph}
\label{fig:example_graph}
\end{figure}

Graphs are often used to represent relationships between objects.
They are represented by a set of nodes (or vertices) and a set of edges, where each edge connects exactly two nodes.
We denote the number of vertices in a graph by $|V|$, and the number of edges by $|E|$.
A graph is \emph{directed} if connections are uni-directional, and \emph{undirected} if they are bi-directional.
One way to encode the information found in a graph is to use what is called an adjacency matrix.
\begin{definition} An adjacency matrix $A$ is a $|V| \times |V|$ matrix where the $(i,j)$-th entry $a_{ij}$ is
\begin{center}
	$a_{ij} = \begin{cases} 1 & \mbox{If an edge connects vertex i to vertex j} \\ 0 & \mbox{otherwise} \end{cases}$
\end{center}
%technically, the definition does not apply to all graphs (according to Wikipedia)
%however, this definition works if we are just considering simple graphs, i.e. at most one edge between any two vertices, no loops
\end{definition}

Every undirected edge can be represented as two directed edges.
Figure \ref{fig:example_graph} shows a simple undirected graph.
It can be represented by the following adjacency matrix.
\[
A = \begin{pmatrix}
0 & 1 & 0 & 0 & 1 & 0\\
1 & 0 & 1 & 0 & 1 & 0\\
0 & 1 & 0 & 1 & 0 & 0\\
0 & 0 & 1 & 0 & 1 & 1\\
1 & 1 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 0
\end{pmatrix}
\]
The adjacency matrix will always be symmetric for undirected graphs.
The diagonal represents self-edges, or edges that connect a node to itself.

Raising the adjacency matrix to a power yields some very interesting information.
We can discover the number of paths of length $n$ between two nodes by raising a graph's adjacency matrix to the $n$th power.
For example, by squaring $A$, we can find the number of paths of length two between every pair of nodes.
\begin{lstlisting}
>>> A = np.array([[0,1,0,0,1,0],[1,0,1,0,1,0],
                  [0,1,0,1,0,0],[0,0,1,0,1,1],
                  [1,1,0,1,0,0],[0,0,0,1,0,0]])

>>> np.linalg.matrix_power(A,2)
array([[2, 1, 1, 1, 1, 0],
       [1, 3, 0, 2, 1, 0],
       [1, 0, 2, 0, 2, 1],
       [1, 2, 0, 3, 0, 0],
       [1, 1, 2, 0, 3, 1],
       [0, 0, 1, 0, 1, 1]])
\end{lstlisting}
We can see that no paths of length two exist between node 0 and node 5 because $A^2_{0,5} = 0$.
By calculating $A^6$ we can find the number of paths of length six from node 3 to itself.
\begin{lstlisting}
>>> np.linalg.matrix_power(A, 6)
array([[45, 54, 38, 45, 54, 16],
       [54, 86, 29, 77, 51, 11],
       [38, 29, 55, 15, 70, 27],
       [45, 77, 15, 75, 31,  4],
       [54, 51, 70, 31, 93, 34],
       [16, 11, 27,  4, 34, 14]])
\end{lstlisting}
We see that there are 75 unique paths of length six from node 3 to itself.
Imagine trying to count all of those paths by hand!
It would be very easy to count incorrectly.
This method makes it very simple to count paths without mistakes.

Adjacency matrices can also be composed of \li{True} and \li{False} values.
In this case, the $n$th power of such a matrix (using boolean arithmetic)
is again a matrix of
boolean values which simply indicate whether there exists a path of length $n$ between the given pair of nodes, rather than indicating the number of such
paths.

\begin{problem}
Let the following matrix represent a directed graph
\[
\begin{pmatrix}
0 & 0 & 1 & 0 & 1 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 1 \\
0 & 1 & 0 & 0 & 0 & 0 & 0
\end{pmatrix}
\]
Between which pair of nodes does there exist the greatest number of paths
of length five?
From which node to which node is there no path of length seven?
\end{problem}

An important question in working with graphs is the degree of its nodes.
The degree of a node is the number of edges that connect to the node.
For a directed graph, each node has an \emph{out-degree} (the number of edges directed away from a node) and an \emph{in-degree} (the number edges directed toward a node).
The \emph{degree matrix} of a graph is a diagonal matrix that has the degree of each node as the diagonal entries (thus, for a directed graph there is an in-degree matrix and an out-degree matrix).

Another useful way of representing an undirected graph is a \emph{Laplacian matrix}.
This special matrix can reveal a lot of information about a graph, which we will see later in this lab.
\begin{definition}
For a simple graph (an undirected graph without self-edges), the Laplacian of a graph $G$ is
\[ L_G = D_G - A_G \]
where $D_G$ is the degree matrix of $G$ and $A_G$ is the adjacency matrix of $G$.
\end{definition}


\begin{problem}
Write a function that accepts the adjacency matrix of a graph as an argument. Use the adjacency matrix to check that the graph is undirected and has no self-edges. Then using the definition above, calcluate the Laplacian matrix.

Test your function by finding the Laplacian matrix of the graph in Figure \ref{fig:example_graph}. Your function should return the following Laplacian matrix:
\[
\begin{pmatrix}
2 &-1 & 0 & 0 &-1 & 0 \\
-1 & 3 &-1 & 0 &-1 & 0 \\
0 &-1 & 2 &-1 & 0 & 0 \\
0 & 0 &-1 & 3 &-1 &-1 \\
-1 &-1 & 0 &-1 & 3 & 0 \\
0 & 0 & 0 &-1 & 0 & 1 \\
\end{pmatrix}
\]
\label{prob:laplacian}
\end{problem}


We may also define \emph{weighted graphs} so that each edge has a weight or cost attached to it.
In this case, the entries of the adjacency matrix are the costs, rather than just ones or zeros.
An example of a weighted graph could be a collection of cities as vertices, roads connecting them as edges, and the distances of the connecting roads as the costs attached to each edge.

In this lab we will learn about the information we can discover about a graph from examining the spectrum of its adjacency matrix and its Laplacian.
While the formulation of the Laplacian matrix seems to be very simple, its structure allows us to learn surprising things by examining its eigenvalues.

For a weighted graph the definition of the Laplacian is as follows.

\begin{definition}  The \emph{degree} of a vertex of a weighted graph is the sum of the weights of the edges connected to that vertex.
In undirected graphs, which is what we will be dealing with, this is the sum of all the weights moving into that vertex.
This definition varies slightly for directed graphs.
Let $D$ be a diagonal matrix with
\[
D_{ii} = \mbox{ Degree of vertex $i$}
\]
and let $A$ be the adjacency matrix of the graph.
The graph \emph{Laplacian} $Q$ is given by
\[
Q = D-A
\]
\end{definition}

The Laplacian matrix of a graph will typically be very sparse.

A \emph{connected graph} is a graph where every vertex is connected to every other vertex by at least one path.
An important question one might ask about a graph is whether or not it is connected.
What is the best way to do this?
A naive approach would be to exhaustively map every possible path from each vertex.
While this would be feasible for very small graphs, most interesting graphs (for example, the internet) will have thousands of vertices, and such an approach becomes essentially impossible to execute.

It turns out there is a better way.
If the second smallest eigenvalue of the Laplacian matrix associated with a graph is positive, then this graph is connected.
The mathematics behind this is quite involved, so we omit a proof for now.
In many applications the Laplacian matrix will be very sparse, and thus with optimizations made for sparsity, we can discover the connectivity of a graph relatively cheaply.

\begin{problem}Write a function \li{laplacian} that accepts an adjacency matrix as an argument and returns the Laplacian matrix and its second smallest eigenvalue.
Use the \li{scipy.linalg} package to compute the eigenvalue.

Use \li{numpy.random.rand(n,n)} to generate two random matrices of sizes n=10 and n=100.
Then use masking to change the sparsity of each of the matrices, i.e. \li{numpy.random.rand(n,n) > c} for \li{c = 0.25,0.95}. This will create four different matrices of boolean values. Remember that when doing calculations with boolean values that \li{True} is considered to be a 1 and \li{False} is considered to be a 0. Is the n=10 adjacency matrix connected when we let c=.25? What about when we let c=.95? Is the n=100 adjacency matrix connected when c=.95?
\end{problem}


\section*{Image Segmentation}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{monuments.png}
\caption{An image and its segments.}
\label{fig:monument}
\end{figure}

An important problem in image processing is that of image segmentation.
When humans observe an image, they can easily pick out portions of an image that ``belong together.''
For example, if we saw the picture of a person against a black background, the pixels making up the background would make up one segment of an image, and the person would make up the other part.
While this seems simple for a human, how can we program a computer to do so? (See Figure \ref{fig:monument} for an example of a segmented image).

First we need to know how to find the adjacency matrix of an image.
An image is a collection of coordinates and light intensities.
We call each coordinate and associated brightness a pixel.
We let every pixel in an image be a vertex in a graph that is connected to its neighbors within a certain radius.
For an $N \times N$ image, we define an adjacency matrix as follows:

\begin{equation}
\label{eq:adjacency}
w_{ij} = e^{-\frac{|I(i) - I(j)|}{\sigma_I^2}} \cdot \begin{cases} e^{-\frac{d(i,j)}{\sigma_d^2}} & \mbox{ for $d(i,j) < r$} \\ 0 & \mbox{ otherwise} \end{cases}
\end{equation}
for $i = 1 \hdots N^2$ and $j = 1 \hdots N^2$ (traveling through each pixel in the image), where
\begin{itemize}
	\item$d(i,j)$ is the Euclidean distance between pixel $i$ and pixel $j$
	\item $|I(i) - I(j)|$ is the difference in brightness of pixels $i$ and $j$
	\item $\sigma_I$ and $\sigma_d$ are constants
	\item $r$ is the radius
\end{itemize}
Thus, given a $N\times N$ image, we will produce an adjacency matrix of size $N^2\times N^2$.
Even for smaller images, this will become very large, but we have sparsity on our side, especially if $r$ is small.
Even so, only do this for images smaller than 50 by 50.

In the following problem we will write a function that finds the adjacency matrix of an image, based on the definition from \eqref{eq:adjacency}. To do this, we first flatten our image being passed in. 

\begin{lstlisting}
nodes = img.flatten()
\end{lstlisting}

This allows us to index all of our pixels or nodes using an one-dimensional array. By doing this, we are better able calculate the weights in-between nodes. It is important to note here that this is only one way of indexing the nodes in our image. We can still index our nodes by using the tuple notation of matrix entries. So for example, given a $2 \times 2$ matrix we can access the bottom-right element, if we are using indexing in Python, by the tuple (1,1). If we choose to flatten our matrix we can simple use the index 3.

Since each pixel is only connected to the pixels within radius $r$ around it, relatively few entries will be non-zero. For this reason, we will want to work with sparse matrices from the \li{scipiy.sparse} package. We initialize our adjacency matrix as a sparse matrix as follows:

\begin{lstlisting}
W = spar.lil_matrix((nodes.size, nodes.size), dtype=float)
\end{lstlisting}

We use \li{lil_matrix} because it gives us an efficent way to build our matrix piece by piece. To learn more about sparse matrices in scipy read the documenation at \url{http://docs.scipy.org/doc/scipy/reference/sparse.html}.

Now we go through each node of our image matrix. A helper function has been provided that finds the pixels and corresponding distances within a given radius of a specific pixel. Note that the pixel or node being passed in is indexed in tuple form, as a given row and column number, while it returns an array of pixels with indices in a flat array form (a single number).


\begin{problem}
Write a function \li{adjacency} that takes an $N \times N$ image array, radius $r$, and values for
$\sigma_I^2$ and $\sigma_d^2$, and returns the adjacency matrix defined in \eqref{eq:adjacency}.
Notice that for each pixel you can save time by only checking the pixels $r$ rows and columns away.
%For that you'll have to handle the pixels on the edges and corners of the image carefully.
%I gave them new helper code, which abstracts away the edge cases.
Make use of sparsity in order to feasibly store such a large matrix.
We have provided code to help out with this problem.
\end{problem}

Once again, we turn to the eigenvalues of the Laplacian matrix.
We examine the second smallest eigenvalue of $D^{-\frac{1}{2}}QD^{-\frac{1}{2}}$, where $D$ is the degree matrix and $Q$ is the Laplacian matrix of the adjacency matrix defined in \eqref{eq:adjacency}.
The associated $N^2 \times 1$ eigenvector will have positive and negative entries, splitting the image into two parts.
Thanks to some very fancy mathematics and the way we have defined the weights between nodes, this does a pretty good job of breaking an image into two segments.
Recursively executing this function, we can find segments within segments.
%Figure \ref{segmentation:example} shows a simple example of an image and its segments.

%\begin{figure}
%\includegraphics[scale=0.2]{monument}
%\includegraphics[scale=0.2]{segment1}
%\includegraphics[scale=0.2]{segment2}
%\caption{An image and it's segments.}
%\label{segmentation:example}
%\end{figure}

\begin{problem}  Write a function \li{segment} that solves the segmentation problem for small images.
Accept an image array as an argument and return the two segments.
Use $r = 5, \sigma_I^2 = 0.02,$ and $\sigma_d^2 = 3.0$.
Remember that the Laplacian matrix will be very large but also very sparse.
Because of the way we defined $\sigma_I^2$ the image matrix intensity values need to be between $0.0$ and $1.0$.
\end{problem}
